### Marking Guide: AT4 Apply Machine Learning to Task Automation

---

``` 
## Objective:
The objective of this assessment is to apply machine learning technologies to automate a task within a workplace environment. The assessment is designed to simulate the capabilities of supervised deep learning models to accomplish a task that is traditionally done manually. Students have the flexibility to select a real-world or simulated scenario that aligns with their interests or career goals.
```

---

## Deliverables 

### 1. Business Understanding:
- **Analyze business needs and establish an initial ML work brief using CRISP-DM methodology.**
- **Define the scope, expected outcomes, and performance criteria for model success.**
- **Confirm work brief and tasks with supervising personnel and relevant organizational policies and procedures.**

``` 
**Assessment Criteria:**
- Completeness and clarity of the work brief.
- Appropriateness of scope and performance criteria.
- Confirmation with relevant personnel and adherence to policies and procedures.
```

### 2. Data Understanding:
- **Satisfy data requirements of the ML work brief following CRISP-DM methodology.**
- **Gather or generate an initial dataset for training and testing.**
- **Identify data issues and explore initial dataset suitability.**

``` 
**Assessment Criteria:**
- Appropriateness and completeness of dataset.
- Identification and handling of data issues.
- Initial exploratory data analysis and visualization efforts.
```

### 3. Data Preparation:
- **Arrange and verify final dataset according to ML work brief requirements following CRISP-DM methodology.**
- **Review applicability of clustering/classification algorithms for unlabelled data.**
- **Perform necessary preprocessing steps on core dataset.**

``` 
**Assessment Criteria:**
- Completeness and appropriateness of data preprocessing.
- Correct grouping and labeling of data.
- Effective use of parameter and feature engineering.
```

### 4. Choose a Supervised Learning Technique:
- **Research and analyze applicability of supervised learning techniques.**
- **Choose at least one supervised learning technique to apply to task automation.**

``` 
**Assessment Criteria:**
- Thoroughness of research and analysis.
- Appropriateness of selected technique for the task and dataset.
- Consideration of task relevance, data suitability, performance, interpretability, and computational efficiency.
```

### 5. Model Development and Training:
- **Confirm expected ML outputs with required personnel.**
- **Set up coding environment and load chosen model.**
- **Conduct training and validation using selected supervised learning technique.**
- **Compare expected and actual outputs.**

``` 
**Assessment Criteria:**
- Confirmation of expected outputs.
- Effectiveness of model setup, training, and validation.
- Accuracy and thoroughness in comparing expected and actual outputs.
```

### 6. Model Evaluation and Task Automation:
- **Evaluate target data outputs against initial performance criteria.**
- **Evaluate model effectiveness using unseen test dataset.**
- **Select relevant metrics for evaluation and document them.**
- **Demonstrate model effectiveness in automating the chosen task.**

``` 
**Assessment Criteria:**
- Appropriateness of evaluation metrics.
- Thoroughness and accuracy in evaluation.
- Effectiveness in task automation and handling unexpected performance.
```

### 7. Documentation and Reflection:
- **Document and comment on each step in the notebook (data processing, model architecture decisions, training processes, evaluation results).**
- **Discuss potential ethical considerations, biases, limitations, and future improvements.**
- **Summarize work in a white paper.**

``` 
**Assessment Criteria:**
- Completeness and clarity of documentation in the notebook.
- Thoroughness in discussing ethical considerations, biases, limitations, and improvements.
- Quality of white paper, including summary, justification, evaluation, discussion of ethical considerations, and reflection.
```

### 8. Secure & Deploy Your Best Model:
- **Publish the best performing model and notebook to Kaggle or Huggingface.**
- **Provide links to the publicly accessible model and notebook.**

``` 
**Assessment Criteria:**
- Successful publication of model and notebook.
- Accessibility and completeness of the published content.
```

### 9. Submission:
- **Export Jupyter notebook as an .ipynb file.**
- **Ensure the notebook runs without errors from start to finish.**
- **Submit the following:**
  1. The complete Jupyter notebook file (.ipynb).
  2. A white paper summarizing the project, methodologies, findings, and reflections.
  3. Documentation of the review process with the lecturer using the provided observation checklist.

``` 
**Instruct students to ensure the following expectations for submission:**
- **Structure and Quality:**
  - The Jupyter notebook should be well-structured, with clear, commented code and markdown cells explaining each step.
  - The white paper should be professional, well-organized, and include the following sections:
    - An abstract summarizing the objective and outcomes.
    - Introduction and business understanding based on CRISP-DM.
    - Data understanding and preparation methods.
    - Explanation of chosen supervised learning technique.
    - Detailed model development, training, and evaluation processes.
    - Discussion of ethical considerations, data governance, and alignment with Australia's AI Ethics Framework.
    - Conclusions, reflections on the process, and potential future improvements.
  - The observation checklist should be fully completed, with remarks and confirmations from the lecturer.

**Assessment Criteria:**
- Exported notebook runs without errors.
- Completeness, clarity, and professional quality of submission materials.
```

---

### Observation Checklist:
Before submission, the student must review the process in-person with the lecturer. This can be done in-class or by appointment. The checklist should be filled out as the student progresses through the assessment task.

- Confirm work brief and tasks with supervising personnel.
- Confirm input machine training data source.
- Confirm data attribute names contain target.
- Confirm default and non-default training parameters control required learning algorithm.
- Confirm data is correctly grouped as labelled or unlabelled.
- Confirm expected ML outputs with required personnel.
- Confirm new algorithm outputs yield accurate results.
- Compare expected and final outputs with required personnel.

``` 
**Assessment Criteria:**
- Completion of checklist items based on process review with lecturer.
```

---

### Marking Criteria:

- **Satisfactory (S)**
- **Not Yet Satisfactory (NYS)**

``` 
**Each task should be evaluated based on the following scales.**
```

---

### Additional Feedback:
``` 
Provide constructive feedback detailing strengths and areas for improvement in each task, encouraging the student to reflect on their learning and application of AI, ML, and DL concepts.
```

